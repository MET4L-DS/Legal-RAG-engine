# ğŸš€ Next Phase: LLM Logic Integration

Iâ€™ll give you a **clear, ordered plan** so you donâ€™t accidentally mix concerns.

---

## ğŸ§­ Phase 4: Answer Intelligence Layer (MOST IMPORTANT)

Right now you have:

- âœ… _What to retrieve_
- âŒ _How to answer like a lawyer_

Your next step is to build a **Legal Answer Orchestrator**, not just â€œpass chunks to LLMâ€.

---

## 1ï¸âƒ£ Query Understanding & Classification (Step 4.1)

Before retrieval, classify the **intent of the question**.

### Why this matters

Legal questions behave very differently:

- â€œWhat is Section 14 BNS?â€ â‰ 
- â€œWhat should police do if FIR is online?â€ â‰ 
- â€œIs this offence bailable?â€

### Implement a lightweight classifier (rule + LLM)

```python
QUERY_TYPES = [
  "definition",
  "procedure",
  "punishment",
  "bailability",
  "jurisdiction",
  "rights_of_victim",
  "police_duty",
  "court_power",
  "compensation",
  "general_explanation"
]
```

This controls:

- retrieval filters
- answer tone
- citation strictness

âš ï¸ Do **not** answer yet â€” only classify.

---

## 2ï¸âƒ£ Retrieval Orchestration (Step 4.2)

You already have **hybrid retrieval**.
Now add **legal priority logic**.

### Retrieval pipeline (final form)

```text
User Query
   â†“
Intent Classification
   â†“
Hybrid Search (FAISS + BM25)
   â†“
Priority Filtering
   â†“
Parent Expansion
   â†“
Dedup + Ordering
```

### Priority Rules (crucial)

1. **Primary legislation** (BNS / BNSS / BSA)
2. **Schemes** (NALSA)
3. **SOPs**

If SOP conflicts with statute:

- statute wins
- SOP is treated as implementation guidance

---

## 3ï¸âƒ£ Parent Expansion Logic (Step 4.3)

You already embedded atomically â€” now **reconstruct hierarchy**.

### Example

If retrieved:

- BNSS Section 8(3)

Auto-include:

- BNSS Section 8 (main heading)

If retrieved:

- Illustration (b)

Auto-include:

- Section rule text

This makes answers:

- complete
- legally safe
- readable

---

## ğŸ§  Phase 5: Legal Answer Generation (THIS IS WHERE QUALITY COMES FROM)

---

## 4ï¸âƒ£ Strict Legal Prompt Template (Step 5.1)

You must **lock the LLM into a legal role**.

### Core system instruction (example)

> You are a legal assistant answering strictly based on provided Indian legal sources.
> Do not assume facts.
> Do not generalize beyond the text.
> Always cite sections verbatim when stating law.

### Answer structure (fixed)

```text
Answer:
<Direct response>

Legal Basis:
â€¢ Section X, Act â€“ quoted or paraphrased strictly

Procedure / Explanation (if applicable):
<Steps>

Important Notes:
<Conditions / exceptions>

Sources:
â€¢ BNS Section X
â€¢ BNSS Section Y
```

This eliminates:

- hallucinations
- vague answers
- â€œAI-soundingâ€ replies

---

## 5ï¸âƒ£ Citation Binding (Step 5.2)

You already solved **retrieval accuracy**.
Now bind answers to **exact chunks**.

Each answer paragraph should map to:

- `chunk_id`
- `law`
- `section`
- `source_file`

This enables:

- clickable citations
- exact highlight rendering
- auditability (huge for legal tools)

---

## ğŸ–¥ï¸ Phase 6: Frontend Contract (Donâ€™t skip this)

---

## 6ï¸âƒ£ Define the API Contract (Step 6.1)

Before writing UI, freeze the response shape:

```json
{
	"answer": "...",
	"sections": [
		{
			"law": "BNSS",
			"section": "173",
			"text": "...",
			"confidence": 0.92
		}
	],
	"procedural_steps": [],
	"warnings": [],
	"sources": []
}
```

Your frontend should **never parse raw LLM text**.

---

## 7ï¸âƒ£ Safety & Scope Guardrails (Step 6.2)

Since this is law:

- Add **non-advisory disclaimer logic**
- Block:
    - personalized legal advice
    - predictions of court outcomes

- Reframe as:

    > â€œAs per the law, the procedure isâ€¦â€

This protects your project if it ever goes public.

---

## ğŸ§ª Phase 7: Lawyer-Grade Testing (Very important)

---

## 8ï¸âƒ£ Legal Test Set (Step 7.1)

Create **30â€“50 canonical queries**, like:

- â€œIs FIR mandatory for cognizable offence?â€
- â€œWhat compensation is available for rape victims?â€
- â€œWho can testify in court?â€

For each:

- expected sections
- expected acts
- no hallucinations allowed

Failing one = fix logic, not prompt.

---

## ğŸ”š What NOT to do next (important)

âŒ Do NOT add more documents yet
âŒ Do NOT tweak embeddings
âŒ Do NOT jump to agents
âŒ Do NOT over-optimize models

Youâ€™re past the hard part already.

---

## ğŸ¯ Recommended Immediate Next Step (DO THIS)

ğŸ‘‰ **Implement Query Classification + Retrieval Orchestration**
This is the backbone of the â€œLLM logic integrationâ€ you marked as next.
